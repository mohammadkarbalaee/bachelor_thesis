{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":191501,"sourceType":"datasetVersion","datasetId":82373},{"sourceId":217337,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":185324,"modelId":207462}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.patches as patches\nfrom sklearn.metrics import precision_recall_curve, average_precision_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom torchvision import transforms\nfrom PIL import Image\nfrom tqdm import tqdm\nimport shutil\nfrom sklearn.metrics import roc_curve, auc\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport os\nimport random\nfrom PIL import Image, ImageEnhance\nfrom tqdm import tqdm\nimport random\nimport math\nimport time\nimport pandas as pd\nfrom collections import Counter\nfrom torchvision import transforms, models\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T02:41:32.852758Z","iopub.execute_input":"2025-01-06T02:41:32.853076Z","iopub.status.idle":"2025-01-06T02:41:32.858482Z","shell.execute_reply.started":"2025-01-06T02:41:32.853047Z","shell.execute_reply":"2025-01-06T02:41:32.857652Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"test_base_dir = \"/kaggle/input/gtsrb-german-traffic-sign\"\ntest_csv_path = f\"{test_base_dir}/Test.csv\"\nmodel_path = \"/kaggle/input/theiss_model/pytorch/default/1/mobilenet_v2_traffic_signs.pth\"\n\n# Load Test Data\ntest_df = pd.read_csv(test_csv_path)\n\n# Custom Dataset Class\nclass CustomDataset(Dataset):\n    def __init__(self, dataframe, base_dir, transform=None):\n        self.dataframe = dataframe\n        self.base_dir = base_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.base_dir, self.dataframe.iloc[idx, -1])\n        label = int(self.dataframe.iloc[idx, -2])\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        return image, label, img_path\n\n\ntest_dataset = CustomDataset(test_df, test_base_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T02:41:39.852045Z","iopub.execute_input":"2025-01-06T02:41:39.852354Z","iopub.status.idle":"2025-01-06T02:41:39.888863Z","shell.execute_reply.started":"2025-01-06T02:41:39.852326Z","shell.execute_reply":"2025-01-06T02:41:39.887966Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Load the Trained Model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\nmodel.classifier[1] = nn.Linear(model.last_channel, 43)  # 43 classes\nmodel.load_state_dict(torch.load(model_path))\nmodel = model.to(device)\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T02:41:42.742964Z","iopub.execute_input":"2025-01-06T02:41:42.743276Z","iopub.status.idle":"2025-01-06T02:41:43.622797Z","shell.execute_reply.started":"2025-01-06T02:41:42.743249Z","shell.execute_reply":"2025-01-06T02:41:43.621915Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n100%|██████████| 13.6M/13.6M [00:00<00:00, 73.1MB/s]\n<ipython-input-8-bae117fd77ef>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path))\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"MobileNetV2(\n  (features): Sequential(\n    (0): Conv2dNormActivation(\n      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6(inplace=True)\n    )\n    (1): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (2): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (3): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (4): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (5): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (6): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (7): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (8): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (9): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (10): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (11): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (12): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (13): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (14): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (15): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (16): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (17): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (18): Conv2dNormActivation(\n      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6(inplace=True)\n    )\n  )\n  (classifier): Sequential(\n    (0): Dropout(p=0.2, inplace=False)\n    (1): Linear(in_features=1280, out_features=43, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Prediction Function\ndef predict(model, image, device):\n    image = image.to(device)\n    with torch.no_grad():\n        output = model(image.unsqueeze(0))  # Add batch dimension\n        probabilities = torch.nn.functional.softmax(output, dim=1)\n        confidence, predicted = probabilities.max(1)\n        return {\"predicted_class\": predicted.item(), \"confidence\": confidence.item()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T02:41:49.251420Z","iopub.execute_input":"2025-01-06T02:41:49.251795Z","iopub.status.idle":"2025-01-06T02:41:49.256337Z","shell.execute_reply.started":"2025-01-06T02:41:49.251767Z","shell.execute_reply":"2025-01-06T02:41:49.255338Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# VANET Classes\nclass NetworkInterface:\n    def __init__(self, car_id):\n        self.car_id = car_id\n        self.rx_queue = []\n\n    def transmit(self, message, cars, communication_range, car_position, road_length):\n        for car in cars:\n            if car.id != self.car_id:\n                distance = self.calculate_distance(car_position, car.x, road_length)\n                if distance <= communication_range:\n                    car.network_interface.receive(message)\n\n    def receive(self, message):\n        self.rx_queue.append(message)\n\n    def process_reception_queue(self):\n        messages = self.rx_queue[:]\n        self.rx_queue.clear()\n        return messages\n\n    @staticmethod\n    def calculate_distance(pos1, pos2, road_length):\n        return min(abs(pos1 - pos2), road_length - abs(pos1 - pos2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T02:41:51.994246Z","iopub.execute_input":"2025-01-06T02:41:51.994582Z","iopub.status.idle":"2025-01-06T02:41:52.000051Z","shell.execute_reply.started":"2025-01-06T02:41:51.994555Z","shell.execute_reply":"2025-01-06T02:41:51.999152Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Brightness change simulation","metadata":{}},{"cell_type":"code","source":"test_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T02:41:55.043356Z","iopub.execute_input":"2025-01-06T02:41:55.043726Z","iopub.status.idle":"2025-01-06T02:41:55.047994Z","shell.execute_reply.started":"2025-01-06T02:41:55.043696Z","shell.execute_reply":"2025-01-06T02:41:55.047028Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def adjust_brightness(image):\n    brightness_factor = random.uniform(0.3, 1.3)\n\n    enhancer = ImageEnhance.Brightness(image)\n    img_enhanced = enhancer.enhance(brightness_factor)\n\n    # img_enhanced.save(\"/kaggle/working/img.png\")\n    return test_transforms(img_enhanced)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T01:49:39.301357Z","iopub.execute_input":"2025-01-06T01:49:39.301577Z","iopub.status.idle":"2025-01-06T01:49:39.313349Z","shell.execute_reply.started":"2025-01-06T01:49:39.301558Z","shell.execute_reply":"2025-01-06T01:49:39.312563Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class Car:\n    def __init__(self, id, x, velocity):\n        self.id = id\n        self.x = x\n        self.velocity = velocity\n        self.received_predictions = []\n        self.network_interface = NetworkInterface(self.id)\n        self.own_prediction = {}\n\n    def move(self, road_length):\n        self.x = (self.x + self.velocity) % road_length\n\n    def make_prediction(self, image):\n        # Convert back to tensor for prediction\n        image_tensor = adjust_brightness(image)\n        self.own_prediction = predict(model, image_tensor, device)\n\n\n    def broadcast(self, cars, communication_range, road_length):\n        message = {\n            \"sender_id\": self.id,\n            \"predicted_class\": self.own_prediction[\"predicted_class\"],\n            \"confidence\": self.own_prediction[\"confidence\"],\n        }\n        self.network_interface.transmit(message, cars, communication_range, self.x, road_length)\n\n    def process_messages(self):\n        received = self.network_interface.process_reception_queue()\n        self.received_predictions.extend(received)\n\n    def calculate_consensus(self):\n        all_predictions = self.received_predictions + [\n            {\"predicted_class\": self.own_prediction[\"predicted_class\"], \"confidence\": self.own_prediction[\"confidence\"]}\n        ]\n        # Step 1: Count occurrences of each class\n        classes = [p[\"predicted_class\"] for p in all_predictions]\n        class_counts = Counter(classes)\n        \n        # Step 2: Group confidences by class\n        confidences = {cls: [] for cls in classes}\n        for p in all_predictions:\n            confidences[p[\"predicted_class\"]].append(p[\"confidence\"])\n        \n        # Step 3: Find the most common class\n        max_count = max(class_counts.values())\n        candidates = [cls for cls, count in class_counts.items() if count == max_count]\n        \n        # Step 4: Resolve ties by selecting the class with the highest average confidence\n        if len(candidates) > 1:\n            avg_confidences = {cls: sum(confidences[cls]) / len(confidences[cls]) for cls in candidates}\n            most_common_class = max(avg_confidences, key=avg_confidences.get)\n        else:\n            most_common_class = candidates[0]\n        \n        # Step 5: Calculate average confidence for the selected class\n        avg_confidence = sum(confidences[most_common_class]) / len(confidences[most_common_class])\n        \n        return {\"predicted_class\": most_common_class, \"confidence\": avg_confidence}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T01:49:39.314209Z","iopub.execute_input":"2025-01-06T01:49:39.314486Z","iopub.status.idle":"2025-01-06T01:49:39.328137Z","shell.execute_reply.started":"2025-01-06T01:49:39.314458Z","shell.execute_reply":"2025-01-06T01:49:39.327342Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Simulation Parameters\nnum_cars = 10\nroad_length = 100\ncommunication_range = 20\ntime_steps = 50\nresults = []\n\n# Initialize Cars\ncars = [Car(id=i, x=random.uniform(0, road_length), velocity=random.uniform(1, 5)) for i in range(num_cars)]\n\n# Simulation Loop\nfor idx, (image_tensor, true_label, img_path) in enumerate(tqdm(test_dataset, desc=\"Processing Images\", total=12630)):\n    total_messages = 0\n    all_received = False\n\n    # if idx >= 10:\n    #     break\n\n    # print(f\"Image {idx + 1}/{len(test_dataset)}: {img_path}\")\n\n    car_predictions = []\n    for car in cars:\n        car.received_predictions.clear()\n        car.network_interface.rx_queue.clear()\n        car.make_prediction(image_tensor)\n        car_predictions.append({\n            \"car_id\": car.id,\n            \"predicted_class\": car.own_prediction[\"predicted_class\"],\n            \"confidence\": car.own_prediction[\"confidence\"]\n        })\n\n    # # Print each car's prediction for the current image\n    # for prediction in car_predictions:\n    #     # print(f\"Car {prediction['car_id']} predicted class {prediction['predicted_class']} with confidence {prediction['confidence']:.2f}\")\n\n    for t in range(time_steps):\n        for car in cars:\n            car.move(road_length)\n        for car in cars:\n            car.broadcast(cars, communication_range, road_length)\n        for car in cars:\n            car.process_messages()\n        if all(len(car.received_predictions) + 1 == len(cars) for car in cars):\n            all_received = True\n            break\n\n    consensus_results = [car.calculate_consensus() for car in cars]\n    most_common_class = Counter([c[\"predicted_class\"] for c in consensus_results]).most_common(1)[0][0]\n    avg_confidence = sum(c[\"confidence\"] for c in consensus_results if c[\"predicted_class\"] == most_common_class) / len(\n        [c for c in consensus_results if c[\"predicted_class\"] == most_common_class]\n    )\n\n    results.append({\n        \"image_id\": idx,\n        \"image_path\": img_path,\n        \"true_label\": true_label,\n        \"total_messages\": sum(len(car.received_predictions) for car in cars),\n        \"all_received\": all_received,\n        \"time_steps\": t + 1,\n        \"final_predicted_class\": most_common_class,\n        \"final_confidence\": avg_confidence,\n    })\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-06T01:49:39.328964Z","iopub.execute_input":"2025-01-06T01:49:39.329222Z","iopub.status.idle":"2025-01-06T02:04:26.725549Z","shell.execute_reply.started":"2025-01-06T01:49:39.329203Z","shell.execute_reply":"2025-01-06T02:04:26.724575Z"}},"outputs":[{"name":"stderr","text":"Processing Images: 100%|██████████| 12630/12630 [14:47<00:00, 14.23it/s]\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Save Results\nresults_df = pd.DataFrame(results)\nresults_df.to_csv(\"vanet_simulation_results.csv\", index=False)\n\n# Accuracy Calculation\ncorrect_predictions = results_df[\"true_label\"] == results_df[\"final_predicted_class\"]\naccuracy = 100.0 * correct_predictions.sum() / len(correct_predictions)\nprint(f\"System Accuracy: {accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T02:04:26.727618Z","iopub.execute_input":"2025-01-06T02:04:26.727876Z","iopub.status.idle":"2025-01-06T02:04:26.802116Z","shell.execute_reply.started":"2025-01-06T02:04:26.727854Z","shell.execute_reply":"2025-01-06T02:04:26.801445Z"}},"outputs":[{"name":"stdout","text":"System Accuracy: 95.46%\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"So basically the brightness did not make any difference at all. it was expected because it barely affectdd the single-use model as well. so in your thesis, write down why your model is so resistent to lighting changes. it's a great finding. ","metadata":{}},{"cell_type":"markdown","source":"# Motion blur simulation scenario","metadata":{}},{"cell_type":"code","source":"from PIL import Image, ImageFilter\n\ndef adjust_motion_blur(image):\n    blur_radius = random.uniform(0.5, 3.0)\n\n    img_blurred = image.filter(ImageFilter.GaussianBlur(blur_radius))\n\n    # img_enhanced.save(\"/kaggle/working/img.png\")\n    return test_transforms(img_blurred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T02:42:41.344265Z","iopub.execute_input":"2025-01-06T02:42:41.344622Z","iopub.status.idle":"2025-01-06T02:42:41.348622Z","shell.execute_reply.started":"2025-01-06T02:42:41.344593Z","shell.execute_reply":"2025-01-06T02:42:41.347832Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"class Car:\n    def __init__(self, id, x, velocity):\n        self.id = id\n        self.x = x\n        self.velocity = velocity\n        self.received_predictions = []\n        self.network_interface = NetworkInterface(self.id)\n        self.own_prediction = {}\n\n    def move(self, road_length):\n        self.x = (self.x + self.velocity) % road_length\n\n    def make_prediction(self, image):\n        # Convert back to tensor for prediction\n        image_tensor = adjust_motion_blur(image)\n        self.own_prediction = predict(model, image_tensor, device)\n\n\n    def broadcast(self, cars, communication_range, road_length):\n        message = {\n            \"sender_id\": self.id,\n            \"predicted_class\": self.own_prediction[\"predicted_class\"],\n            \"confidence\": self.own_prediction[\"confidence\"],\n        }\n        self.network_interface.transmit(message, cars, communication_range, self.x, road_length)\n\n    def process_messages(self):\n        received = self.network_interface.process_reception_queue()\n        self.received_predictions.extend(received)\n\n    def calculate_consensus(self):\n        all_predictions = self.received_predictions + [\n            {\"predicted_class\": self.own_prediction[\"predicted_class\"], \"confidence\": self.own_prediction[\"confidence\"]}\n        ]\n        # Step 1: Count occurrences of each class\n        classes = [p[\"predicted_class\"] for p in all_predictions]\n        class_counts = Counter(classes)\n        \n        # Step 2: Group confidences by class\n        confidences = {cls: [] for cls in classes}\n        for p in all_predictions:\n            confidences[p[\"predicted_class\"]].append(p[\"confidence\"])\n        \n        # Step 3: Find the most common class\n        max_count = max(class_counts.values())\n        candidates = [cls for cls, count in class_counts.items() if count == max_count]\n        \n        # Step 4: Resolve ties by selecting the class with the highest average confidence\n        if len(candidates) > 1:\n            avg_confidences = {cls: sum(confidences[cls]) / len(confidences[cls]) for cls in candidates}\n            most_common_class = max(avg_confidences, key=avg_confidences.get)\n        else:\n            most_common_class = candidates[0]\n        \n        # Step 5: Calculate average confidence for the selected class\n        avg_confidence = sum(confidences[most_common_class]) / len(confidences[most_common_class])\n        \n        return {\"predicted_class\": most_common_class, \"confidence\": avg_confidence}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T02:42:09.617505Z","iopub.execute_input":"2025-01-06T02:42:09.617795Z","iopub.status.idle":"2025-01-06T02:42:09.625766Z","shell.execute_reply.started":"2025-01-06T02:42:09.617775Z","shell.execute_reply":"2025-01-06T02:42:09.624928Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Simulation Parameters\nnum_cars = 10\nroad_length = 100\ncommunication_range = 20\ntime_steps = 50\nresults = []\n\n# Initialize Cars\ncars = [Car(id=i, x=random.uniform(0, road_length), velocity=random.uniform(1, 5)) for i in range(num_cars)]\n\n# Simulation Loop\nfor idx, (image_tensor, true_label, img_path) in enumerate(tqdm(test_dataset, desc=\"Processing Images\", total=12630)):\n    total_messages = 0\n    all_received = False\n\n    # if idx >= 10:\n    #     break\n\n    # print(f\"Image {idx + 1}/{len(test_dataset)}: {img_path}\")\n\n    car_predictions = []\n    for car in cars:\n        car.received_predictions.clear()\n        car.network_interface.rx_queue.clear()\n        car.make_prediction(image_tensor)\n        car_predictions.append({\n            \"car_id\": car.id,\n            \"predicted_class\": car.own_prediction[\"predicted_class\"],\n            \"confidence\": car.own_prediction[\"confidence\"]\n        })\n\n    # # Print each car's prediction for the current image\n    # for prediction in car_predictions:\n    #     # print(f\"Car {prediction['car_id']} predicted class {prediction['predicted_class']} with confidence {prediction['confidence']:.2f}\")\n\n    for t in range(time_steps):\n        for car in cars:\n            car.move(road_length)\n        for car in cars:\n            car.broadcast(cars, communication_range, road_length)\n        for car in cars:\n            car.process_messages()\n        if all(len(car.received_predictions) + 1 == len(cars) for car in cars):\n            all_received = True\n            break\n\n    consensus_results = [car.calculate_consensus() for car in cars]\n    most_common_class = Counter([c[\"predicted_class\"] for c in consensus_results]).most_common(1)[0][0]\n    avg_confidence = sum(c[\"confidence\"] for c in consensus_results if c[\"predicted_class\"] == most_common_class) / len(\n        [c for c in consensus_results if c[\"predicted_class\"] == most_common_class]\n    )\n\n    results.append({\n        \"image_id\": idx,\n        \"image_path\": img_path,\n        \"true_label\": true_label,\n        \"total_messages\": sum(len(car.received_predictions) for car in cars),\n        \"all_received\": all_received,\n        \"time_steps\": t + 1,\n        \"final_predicted_class\": most_common_class,\n        \"final_confidence\": avg_confidence,\n    })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T02:42:44.845285Z","iopub.execute_input":"2025-01-06T02:42:44.845623Z","iopub.status.idle":"2025-01-06T02:58:40.121674Z","shell.execute_reply.started":"2025-01-06T02:42:44.845595Z","shell.execute_reply":"2025-01-06T02:58:40.120853Z"}},"outputs":[{"name":"stderr","text":"Processing Images: 100%|██████████| 12630/12630 [15:55<00:00, 13.22it/s]\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Save Results\nresults_df = pd.DataFrame(results)\nresults_df.to_csv(\"vanet_simulation_results.csv\", index=False)\n\n# Accuracy Calculation\ncorrect_predictions = results_df[\"true_label\"] == results_df[\"final_predicted_class\"]\naccuracy = 100.0 * correct_predictions.sum() / len(correct_predictions)\nprint(f\"System Accuracy: {accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T03:00:58.375971Z","iopub.execute_input":"2025-01-06T03:00:58.376267Z","iopub.status.idle":"2025-01-06T03:00:58.461524Z","shell.execute_reply.started":"2025-01-06T03:00:58.376243Z","shell.execute_reply":"2025-01-06T03:00:58.460683Z"}},"outputs":[{"name":"stdout","text":"System Accuracy: 66.37%\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"slight performance boost. write it in your thesis. it's worthwhile","metadata":{}},{"cell_type":"markdown","source":"# Angle and rotation","metadata":{}},{"cell_type":"code","source":"from PIL import Image\n\ndef adjust_rotation(image):\n    random_angle = random.uniform(-45, 45)\n    \n    rotated_image = image.rotate(random_angle, resample=Image.BICUBIC, expand=True)\n\n    # img_enhanced.save(\"/kaggle/working/img.png\")\n    return test_transforms(rotated_image)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T03:06:32.332514Z","iopub.execute_input":"2025-01-06T03:06:32.332839Z","iopub.status.idle":"2025-01-06T03:06:32.336872Z","shell.execute_reply.started":"2025-01-06T03:06:32.332811Z","shell.execute_reply":"2025-01-06T03:06:32.336050Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"class Car:\n    def __init__(self, id, x, velocity):\n        self.id = id\n        self.x = x\n        self.velocity = velocity\n        self.received_predictions = []\n        self.network_interface = NetworkInterface(self.id)\n        self.own_prediction = {}\n\n    def move(self, road_length):\n        self.x = (self.x + self.velocity) % road_length\n\n    def make_prediction(self, image):\n        # Convert back to tensor for prediction\n        image_tensor = adjust_rotation(image)\n        self.own_prediction = predict(model, image_tensor, device)\n\n\n    def broadcast(self, cars, communication_range, road_length):\n        message = {\n            \"sender_id\": self.id,\n            \"predicted_class\": self.own_prediction[\"predicted_class\"],\n            \"confidence\": self.own_prediction[\"confidence\"],\n        }\n        self.network_interface.transmit(message, cars, communication_range, self.x, road_length)\n\n    def process_messages(self):\n        received = self.network_interface.process_reception_queue()\n        self.received_predictions.extend(received)\n\n    def calculate_consensus(self):\n        all_predictions = self.received_predictions + [\n            {\"predicted_class\": self.own_prediction[\"predicted_class\"], \"confidence\": self.own_prediction[\"confidence\"]}\n        ]\n        # Step 1: Count occurrences of each class\n        classes = [p[\"predicted_class\"] for p in all_predictions]\n        class_counts = Counter(classes)\n        \n        # Step 2: Group confidences by class\n        confidences = {cls: [] for cls in classes}\n        for p in all_predictions:\n            confidences[p[\"predicted_class\"]].append(p[\"confidence\"])\n        \n        # Step 3: Find the most common class\n        max_count = max(class_counts.values())\n        candidates = [cls for cls, count in class_counts.items() if count == max_count]\n        \n        # Step 4: Resolve ties by selecting the class with the highest average confidence\n        if len(candidates) > 1:\n            avg_confidences = {cls: sum(confidences[cls]) / len(confidences[cls]) for cls in candidates}\n            most_common_class = max(avg_confidences, key=avg_confidences.get)\n        else:\n            most_common_class = candidates[0]\n        \n        # Step 5: Calculate average confidence for the selected class\n        avg_confidence = sum(confidences[most_common_class]) / len(confidences[most_common_class])\n        \n        return {\"predicted_class\": most_common_class, \"confidence\": avg_confidence}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T03:06:52.164976Z","iopub.execute_input":"2025-01-06T03:06:52.165302Z","iopub.status.idle":"2025-01-06T03:06:52.173373Z","shell.execute_reply.started":"2025-01-06T03:06:52.165272Z","shell.execute_reply":"2025-01-06T03:06:52.172394Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Simulation Parameters\nnum_cars = 10\nroad_length = 100\ncommunication_range = 20\ntime_steps = 50\nresults = []\n\n# Initialize Cars\ncars = [Car(id=i, x=random.uniform(0, road_length), velocity=random.uniform(1, 5)) for i in range(num_cars)]\n\n# Simulation Loop\nfor idx, (image_tensor, true_label, img_path) in enumerate(tqdm(test_dataset, desc=\"Processing Images\", total=12630)):\n    total_messages = 0\n    all_received = False\n\n    # if idx >= 10:\n    #     break\n\n    # print(f\"Image {idx + 1}/{len(test_dataset)}: {img_path}\")\n\n    car_predictions = []\n    for car in cars:\n        car.received_predictions.clear()\n        car.network_interface.rx_queue.clear()\n        car.make_prediction(image_tensor)\n        car_predictions.append({\n            \"car_id\": car.id,\n            \"predicted_class\": car.own_prediction[\"predicted_class\"],\n            \"confidence\": car.own_prediction[\"confidence\"]\n        })\n\n    # # Print each car's prediction for the current image\n    # for prediction in car_predictions:\n    #     # print(f\"Car {prediction['car_id']} predicted class {prediction['predicted_class']} with confidence {prediction['confidence']:.2f}\")\n\n    for t in range(time_steps):\n        for car in cars:\n            car.move(road_length)\n        for car in cars:\n            car.broadcast(cars, communication_range, road_length)\n        for car in cars:\n            car.process_messages()\n        if all(len(car.received_predictions) + 1 == len(cars) for car in cars):\n            all_received = True\n            break\n\n    consensus_results = [car.calculate_consensus() for car in cars]\n    most_common_class = Counter([c[\"predicted_class\"] for c in consensus_results]).most_common(1)[0][0]\n    avg_confidence = sum(c[\"confidence\"] for c in consensus_results if c[\"predicted_class\"] == most_common_class) / len(\n        [c for c in consensus_results if c[\"predicted_class\"] == most_common_class]\n    )\n\n    results.append({\n        \"image_id\": idx,\n        \"image_path\": img_path,\n        \"true_label\": true_label,\n        \"total_messages\": sum(len(car.received_predictions) for car in cars),\n        \"all_received\": all_received,\n        \"time_steps\": t + 1,\n        \"final_predicted_class\": most_common_class,\n        \"final_confidence\": avg_confidence,\n    })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T03:07:11.824810Z","iopub.execute_input":"2025-01-06T03:07:11.825096Z","iopub.status.idle":"2025-01-06T03:22:38.684026Z","shell.execute_reply.started":"2025-01-06T03:07:11.825074Z","shell.execute_reply":"2025-01-06T03:22:38.683162Z"}},"outputs":[{"name":"stderr","text":"Processing Images: 100%|██████████| 12630/12630 [15:26<00:00, 13.63it/s]\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Save Results\nresults_df = pd.DataFrame(results)\nresults_df.to_csv(\"vanet_simulation_results.csv\", index=False)\n\n# Accuracy Calculation\ncorrect_predictions = results_df[\"true_label\"] == results_df[\"final_predicted_class\"]\naccuracy = 100.0 * correct_predictions.sum() / len(correct_predictions)\nprint(f\"System Accuracy: {accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T03:23:11.764994Z","iopub.execute_input":"2025-01-06T03:23:11.765307Z","iopub.status.idle":"2025-01-06T03:23:11.843805Z","shell.execute_reply.started":"2025-01-06T03:23:11.765280Z","shell.execute_reply":"2025-01-06T03:23:11.842865Z"}},"outputs":[{"name":"stdout","text":"System Accuracy: 77.66%\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"results_df[10:20]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T03:26:03.883070Z","iopub.execute_input":"2025-01-06T03:26:03.883345Z","iopub.status.idle":"2025-01-06T03:26:03.893272Z","shell.execute_reply.started":"2025-01-06T03:26:03.883322Z","shell.execute_reply":"2025-01-06T03:26:03.892322Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"    image_id                                         image_path  true_label  \\\n10        10  /kaggle/input/gtsrb-german-traffic-sign/Test/0...          12   \n11        11  /kaggle/input/gtsrb-german-traffic-sign/Test/0...           7   \n12        12  /kaggle/input/gtsrb-german-traffic-sign/Test/0...          23   \n13        13  /kaggle/input/gtsrb-german-traffic-sign/Test/0...           7   \n14        14  /kaggle/input/gtsrb-german-traffic-sign/Test/0...           4   \n15        15  /kaggle/input/gtsrb-german-traffic-sign/Test/0...           9   \n16        16  /kaggle/input/gtsrb-german-traffic-sign/Test/0...          21   \n17        17  /kaggle/input/gtsrb-german-traffic-sign/Test/0...          20   \n18        18  /kaggle/input/gtsrb-german-traffic-sign/Test/0...          27   \n19        19  /kaggle/input/gtsrb-german-traffic-sign/Test/0...          38   \n\n    total_messages  all_received  time_steps  final_predicted_class  \\\n10            1884         False          50                     12   \n11            2012         False          50                      7   \n12            1604         False          50                     23   \n13            1866         False          50                      7   \n14            1664         False          50                      4   \n15            1548         False          50                     32   \n16            2270         False          50                     20   \n17            1862         False          50                     20   \n18            2060         False          50                     27   \n19            1884         False          50                     38   \n\n    final_confidence  \n10          0.769514  \n11          0.972472  \n12          0.718060  \n13          0.994168  \n14          0.991494  \n15          0.720205  \n16          0.235127  \n17          0.746733  \n18          0.988319  \n19          0.874092  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>image_path</th>\n      <th>true_label</th>\n      <th>total_messages</th>\n      <th>all_received</th>\n      <th>time_steps</th>\n      <th>final_predicted_class</th>\n      <th>final_confidence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>/kaggle/input/gtsrb-german-traffic-sign/Test/0...</td>\n      <td>12</td>\n      <td>1884</td>\n      <td>False</td>\n      <td>50</td>\n      <td>12</td>\n      <td>0.769514</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>/kaggle/input/gtsrb-german-traffic-sign/Test/0...</td>\n      <td>7</td>\n      <td>2012</td>\n      <td>False</td>\n      <td>50</td>\n      <td>7</td>\n      <td>0.972472</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>/kaggle/input/gtsrb-german-traffic-sign/Test/0...</td>\n      <td>23</td>\n      <td>1604</td>\n      <td>False</td>\n      <td>50</td>\n      <td>23</td>\n      <td>0.718060</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>/kaggle/input/gtsrb-german-traffic-sign/Test/0...</td>\n      <td>7</td>\n      <td>1866</td>\n      <td>False</td>\n      <td>50</td>\n      <td>7</td>\n      <td>0.994168</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>/kaggle/input/gtsrb-german-traffic-sign/Test/0...</td>\n      <td>4</td>\n      <td>1664</td>\n      <td>False</td>\n      <td>50</td>\n      <td>4</td>\n      <td>0.991494</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>/kaggle/input/gtsrb-german-traffic-sign/Test/0...</td>\n      <td>9</td>\n      <td>1548</td>\n      <td>False</td>\n      <td>50</td>\n      <td>32</td>\n      <td>0.720205</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>/kaggle/input/gtsrb-german-traffic-sign/Test/0...</td>\n      <td>21</td>\n      <td>2270</td>\n      <td>False</td>\n      <td>50</td>\n      <td>20</td>\n      <td>0.235127</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>/kaggle/input/gtsrb-german-traffic-sign/Test/0...</td>\n      <td>20</td>\n      <td>1862</td>\n      <td>False</td>\n      <td>50</td>\n      <td>20</td>\n      <td>0.746733</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>/kaggle/input/gtsrb-german-traffic-sign/Test/0...</td>\n      <td>27</td>\n      <td>2060</td>\n      <td>False</td>\n      <td>50</td>\n      <td>27</td>\n      <td>0.988319</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>/kaggle/input/gtsrb-german-traffic-sign/Test/0...</td>\n      <td>38</td>\n      <td>1884</td>\n      <td>False</td>\n      <td>50</td>\n      <td>38</td>\n      <td>0.874092</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"markdown","source":"it's good. let's see how the model itself performs alone. ","metadata":{}}]}